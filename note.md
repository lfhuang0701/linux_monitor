# 一级标题

## 项目出发点是什么

为了实时检测负载，cpu使用率，内存等状态，进而排查异常情况，且相对于top等系统命令，可视化程度更高，且能够详细显示多个核心的负载，便于分析

## 项目亮点

1. 分布式监控
2. monitor模块使用到了c++的特性

## 可能的问题

1. grpc模块：grpc底层原理，tcp，udp等计算机网络和网络编程相关知识
2. protobuf模块：protobuf序列化协议底层原理，和xml，jason相比的优缺点；基本使用
3.

## 项目难点或者遇到的问题

### 内存泄漏问题

使用new申请的内存，没有delete掉，后面改用智能指针，方便管理

### gdb调试

### docker遇到的问题

1. 项目构建时，需要安装开源的库，如grpc，proto，但是在源码构建时遇到很多错误，如缺少依赖库，源码构建时环境变量的设置，需要查看官方文档（如何使用cmake构建）的安装方法，以及根据报错查找解决方法
2. dockerfile的编写；在dockerfile build过程中，需要一步步进行添加，多个库之间有依赖关系，所以经常遇到缺少依赖库的情况，然后我查看官方文档，搜索所依赖的库进行安装，然后我在前面安装所依赖的库，但是本来docker file的构建就很慢，然后缺少依赖库的情况经常出现，需要不断的添加dockerfile代码然后重新构建，就导致构建过程很耗费时间，后来我在出错位置的前一行安装依赖库，那么之前已经构建好的就不用重新构建，缩短了构建的时间，当然这是在调试阶段，在成功构建后，重新整合了docker file的编写顺序，最后成功构建了镜像。
3. 刚开始构建镜像文件时，文件过大，需要压缩镜像文件大小，在proto库和grpc库的安装脚本中，安装完毕后删除解压缩的包。
4. 在docker file中，会将本地目录下的proto，grpc安装包及脚本拷贝到镜像目录下，然后运行安装脚本，因此在安装脚本中需要切换目录到镜像文件目录下proto所在目录
5. 运行容器时，docker run 中环境变量的设置，这里需要添加许多环境变量，否则很多功能无法使用，比如如果想使用qt，就要添加display变量，这些也都是通过报错，然后搜索报错信息，参考别人的解决方法进行解决的

### grpc、proto遇到的问题

1. grpc的使用，在GitHub找到grpc的代码仓库，根据提供的例程学习如何使用grpc，源码学习的困难
2. 编写grpc的server端和client端时，遇到很多问题，主要参考官方给定例程及其他人的解决方法修改代码，
3. client与server功能验证的困难， 编写完成过先用netstat -tap指令测试server端与client端的功能是否正常，先不要把client生成库，生成可执行程序，如何启动client和server，发生一些数据判断通信是否正常
4. 官方给的例程中proto编译工具不是cmake，是bzael，因此需要学习用cmake编译构建proto文件，编写cmakelist时需要不断试错，根据错误完善cmakelist，比如说编译时需要链接grpc的库，但是报错是没有找到gpc的库，后面查找发现需要先find_package到grpc的包，才能链接grpc的库
5. 如何书写proto文件中数据结构，比如有的成员需要使用repeated关键字，并且需要把书写的数据结构整合到一起
6. 如何书写proto文件中的服务，和一些接口

### grpc遇到的问题

1. grpc的使用，在GitHub找到grpc的代码仓库，根据提供的例程学习如何使用grpc

### qt遇到的问题

1. 在设计QT界面时，主函数内刚开始使用thead->join（）阻塞地等待线程，而无法继续执行app.exec()，进而导致错误，后续查阅资料后采用thread->detach()实行线程分离，问题解决
2. 在设计QT界面时，如果想使用信号槽，需要添加Q_OBJECT,同时编译时要添加`set_target_properties(display PROPERTIES AUTOMOC TRUE)`， 否则会报错

## docker模块

1. 容器是如何实现的，底层技术是什么？
   容器的底层原理是namespace和cgroup，他们是linux的内核功能。容器可以利用namespace实现容器之间以及容器与主机之间的资源隔离，比如进程，文件系统，网络等。利用cgroup技术实现对容器内的资源进行分配和限制，比如内存，cpu资源，防止耗尽资源影响到其他容器和主机。

## protobuf模块

1. 为什么使用protobuf序列化协议？有没有其他的序列化协议，优缺点在哪里？
   其他的序列化协议如XML，JASON，protobuf的优点有：序列化数据简洁，空间开销低；解析速度快，实时性较高；有标准的IDL和IDL编译器，更加规范；提供动态库，反序列化仅需一行代码。
2. 序列化及反序列的底层原理？
   典型的序列化及反序列化过程常用到几个组件：
   （1）IDL文件：参与通信的双方需要对通信内容的数据结构做相关的约定，这种约定需要与开发语言和平台无关，采用接口描述语言撰写的这种约定成为IDL文件。
   （2）IDL编译器：IDL编译器将IDL文件转换为各开发语言对应的动态库
   （3）负责序列化和反序列化的代码（Stub和Skeleton）：分别部署到客户端和服务端，一方面接收应用层数据，序列化后发送到传输层，一方面接收传输层数据，反序列化后发送给应用层。
   （4）客户端服务端：应用层代码，面对的是各对应语言的数据结构
3. proto文件存放什么，有什么作用？
   在proto文件中定义需要的类，包含网络信息，cpu负载，cpu状态，cpu软中断，内存信息，然后在一个monitor_info类中集成这些类，最后通过proto编译器编译生成pb.h和pb.cc文件，在业务代码内引入头文件即可使用proto编译生成c++类及处理类的方法（主要包含对定义类的设置与获取），同时也能够直接调用接口使用序列化及反序列化方法

## monitor模块

1. 为什么要进行性能分析，为什么要看cpu的负载情况？
   答：在后端开发中，要关注负载的变化趋势，一旦负载过高，就可能导致进程响应变慢，进而影响服务的正常功能。使用top命令可以查看当前负载，而将负载信息记录下来，可以更好的结合历史数据进行分析和调查
2. 为什么要看三个时间平均负载？与top命令相比有何优势
   答：能够分析系统负载的变化趋势，进而更全面，更立体地理解目前的负载情况。与top命令相比，可以存放历史负载数据进而全面分析，且客户端可部署到其它主机进而监测其它主机的负载情况
3. 平均负载和CPU使用率之间的关系
   答：平均负载是指单位时间内，处于运行状态和不可中断状态的进程数，这里的进程包括使用cpu的进程，等待cpu的进程，等待IO的进程，而 CPU 使用率，是单位时间内 CPU 繁忙情况的统计，跟平均负载并不一定完全对应。比如：CPU 密集型进程，使用大量 CPU 会导致平均负载升高，此时这两者是一致的；I/O 密集型进程，等待 I/O 也会导致平均负载升高，但 CPU 使用率不一定很高；大量等待 CPU 的进程调度也会导致平均负载升高，此时的 CPU 使用率也会比较高
4. 关于中断，什么是硬中断，什么是软中断，上半部，下半部
   答：①中断是一种异步处理事件的机制，当cpu执行程序时，发生了一件需要立即处理的事件，cpu会暂停程序转而处理事件，执行结束后返回继续执行程序。
   ②当中断发生时，通常会屏蔽其他中断，因此为了不丢失其他中断，需要中断服务程序快速执行，占用较少的cpu时间
   ③由此，Linux将中断分为上半部和下半部，上半部执行需要立即执行的操作，代码运行在中断上下文，执行时间较短，通常是处理硬件的请求，因此称为硬中断；下半部特点就是延迟执行，是对上半部的后续处理，由内核触发，代码运行在内核，因此被称为软中断，但软中断不仅仅指的是下半部，由内核自定义触发的事件也称为软中断
5. cpu使用满了如何排查
   答：从平均负载，cpu使用率，cpu中断方面逐步排查
6. 内存主要监测了哪些部分，buffer和cache的区别是什么？
   总内存大小，已使用和未使用内存的大小，共享内存的大小，以及缓存和缓冲区的大小；buffer是缓存，是对磁盘块的临时存储，内核可以把要写入磁盘的数据先放入buffer，而后同一写入磁盘，因此可以将多次小的写合并为单次大的写。cache为缓冲区，是从磁盘读取数据的页缓存，这样近期再次访问这些数据时，就可以直接从内存读取，而不需要再次访问缓慢的磁盘。
7. 监测模块是如何获取数据的？
   通过读取“/proc"目录下的文件内容获取数据，如loadvag，stat，softirqs等，并根据各文件内容格式编写函数进行读取，并使用读取到的数据更新protobuf消息

## rpc_manager模块

1. gRPC服务端与客户端是如何通信的？
   使用protobuf语法在.proto文件张定义服务接口和消息类型，然后使用protobuf编译器从proto文件生成服务端和客户端的代码，然后客户端和服务端各自实现其定义的服务接口，客户端需要创建一个与服务端通信的通道（channel）,接着创建grpc存根用于发起grpc远程调用，服务端会创建一个gRPC服务器对象；客户端使用通道与服务端建立连接，连接需要指定本地端口号和服务端ip地址，客户端通过存根调用RPC，并将请求序列化后发送到服务端，服务端反序列化请求后会调用相应的服务方法，并将响应序列化后发送到客户端。在通信过程中，若发送错误（网络问题，序列化问题），gRPC会返回错误状态和详细信息。RPC调用完成后，客户端和服务端会进行资源清理，包含关闭通道，释放内存等
2. 在 gRPC 中，如果服务端或客户端发生故障，它们是如何进行故障恢复的？
   （1）每个RPC调用都可以设置超时时间，若超时后没有响应，则调用将被取消，且客户端会收到超时错误
   （2）客户端若连接失败，可以自动尝试重新建立连接
3. grpc通信是如何保证传输安全性的？
   （1）gRPC支持使用传输层协议TLS来加密通信
   （2）HTTP2.0的特性本身支持一些安全特性
4. gRPC中，客户端和服务端发起rpc调用的流程是什么？

Kimi: gRPC 调用的基本流程在客户端和服务端都有几个共同的步骤，但也有各自特定的任务。以下是客户端和服务端发起 gRPC 调用的基本流程：

### 客户端流程：

1. **定义 Protobuf 接口**：
   使用 Protocol Buffers 语法在 `.proto` 文件中定义服务接口和消息类型。
2. **生成代码**：
   使用 `protoc` 编译器生成客户端和服务端的代码。
3. **创建 Channel**：
   创建一个 gRPC 通道（`Channel`），用于与服务端建立连接。
4. **创建 Stub**：
   使用通道创建一个存根（`Stub`），它包含了对服务端 RPC 方法的本地代理。
5. **创建 ClientContext**：
   创建一个客户端上下文（`ClientContext`），它包含了调用的元数据，如超时设置、取消令牌等。
6. **调用 RPC 方法**：
   通过存根调用 RPC 方法，传入客户端上下文和请求消息。
7. **接收响应**：
   接收来自服务端的响应消息。
8. **检查状态**：
   检查调用的状态，处理成功或失败的情况。
9. **清理资源**：
   清理使用的资源，如关闭通道。

### 服务端流程：

1. **定义 Protobuf 接口**：
   与客户端相同，使用 `.proto` 文件定义服务接口。
2. **生成服务端代码**：
   使用 `protoc` 编译器生成服务端代码。
3. **创建服务实现**：
   创建服务接口的实现类，实现所有 RPC 方法。
4. **创建 ServerBuilder**：
   使用 `ServerBuilder` 来配置服务端。
5. **注册服务**：
   将服务实现注册到 `ServerBuilder`。
6. **配置端口和凭证**：
   配置服务端监听的端口和使用的凭证（如 TLS/SSL 凭证）。
7. **构建并启动服务端**：
   使用 `ServerBuilder` 构建并启动服务端。
8. **等待调用**：
   服务端等待客户端的 RPC 调用请求。
9. **处理请求**：
   服务端接收请求并根据请求类型调用相应的 RPC 方法。
10. **发送响应**：
    服务端处理完请求后，发送响应回客户端。
11. **关闭服务端**：
    在适当的时候关闭服务端，释放资源。


## 考察秋招项目及岗位选择

![1717423328618](images/note/1717423328618.png)

![1717507223480](images/note/1717507223480.png)
